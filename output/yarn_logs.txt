[root@sandbox-hdp usr]# spark-submit test.py
18/07/30 00:36:38 INFO SparkContext: Running Spark version 2.2.0.2.6.4.0-91
18/07/30 00:36:38 INFO SparkContext: Submitted application: bids
18/07/30 00:36:39 INFO SecurityManager: Changing view acls to: root
18/07/30 00:36:39 INFO SecurityManager: Changing modify acls to: root
18/07/30 00:36:39 INFO SecurityManager: Changing view acls groups to:
18/07/30 00:36:39 INFO SecurityManager: Changing modify acls groups to:
18/07/30 00:36:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
18/07/30 00:36:39 INFO Utils: Successfully started service 'sparkDriver' on port 38373.
18/07/30 00:36:39 INFO SparkEnv: Registering MapOutputTracker
18/07/30 00:36:39 INFO SparkEnv: Registering BlockManagerMaster
18/07/30 00:36:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/07/30 00:36:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/07/30 00:36:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-16c763bd-a875-4344-a3ad-37cab14ba600
18/07/30 00:36:39 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/07/30 00:36:40 INFO SparkEnv: Registering OutputCommitCoordinator
18/07/30 00:36:40 INFO log: Logging initialized @5173ms
18/07/30 00:36:40 INFO Server: jetty-9.3.z-SNAPSHOT
18/07/30 00:36:40 INFO Server: Started @5280ms
18/07/30 00:36:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/07/30 00:36:40 INFO AbstractConnector: Started ServerConnector@2170f1fc{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
18/07/30 00:36:40 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3f66e4aa{/jobs,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@710b6cac{/jobs/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6d5aa152{/jobs/job,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@25aa95a0{/jobs/job/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@60a80aa7{/stages,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@65ab33eb{/stages/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4f3dec11{/stages/stage,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@448b29d4{/stages/stage/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3a3737b1{/stages/pool,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@732c922f{/stages/pool/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4fc0cc6f{/storage,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@10cb5821{/storage/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5aec31db{/storage/rdd,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1f3abc9f{/storage/rdd/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@66432a9{/environment,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4e6ac494{/environment/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@39204736{/executors,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@57082507{/executors/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@448dc67e{/executors/threadDump,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6d6a64e4{/executors/threadDump/json,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@41ed8e53{/static,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5f368f63{/,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@230d4969{/api,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@17e0b0e8{/jobs/job/kill,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@24e4a3a9{/stages/stage/kill,null,AVAILABLE,@Spark}
18/07/30 00:36:40 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4041
18/07/30 00:36:40 INFO SparkContext: Added file file:/usr/test.py at spark://172.17.0.2:38373/files/test.py with timestamp 1532911000894
18/07/30 00:36:40 INFO Utils: Copying /usr/test.py to /tmp/spark-5454d56e-73fb-462a-b5b1-4c2d826cee9d/userFiles-2c7eb7f1-a022-432e-9bf1-279d525fd99c/test.py
18/07/30 00:36:41 INFO RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.17.0.2:8032
18/07/30 00:36:41 INFO Client: Requesting a new application from cluster with 1 NodeManagers
18/07/30 00:36:42 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (2250 MB per container)
18/07/30 00:36:42 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
18/07/30 00:36:42 INFO Client: Setting up container launch context for our AM
18/07/30 00:36:42 INFO Client: Setting up the launch environment for our AM container
18/07/30 00:36:42 INFO Client: Preparing resources for our AM container
18/07/30 00:36:43 INFO Client: Use hdfs cache file as spark.yarn.archive for HDP, hdfsCacheFile:hdfs://sandbox-hdp.hortonworks.com:8020/hdp/apps/2.6.4.0-91/spark2/spark2-hdp-yarn-archive.tar.gz
18/07/30 00:36:43 INFO Client: Source and destination file systems are the same. Not copying hdfs://sandbox-hdp.hortonworks.com:8020/hdp/apps/2.6.4.0-91/spark2/spark2-hdp-yarn-archive.tar.gz
18/07/30 00:36:43 INFO Client: Uploading resource file:/tmp/spark-5454d56e-73fb-462a-b5b1-4c2d826cee9d/__spark_conf__2677481321733684925.zip -> hdfs://sandbox-hdp.hortonworks.com:8020/user/root/.sparkStaging/application_1532879321912_0025/__spark_conf__.zip
18/07/30 00:36:43 INFO SecurityManager: Changing view acls to: root
18/07/30 00:36:43 INFO SecurityManager: Changing modify acls to: root
18/07/30 00:36:43 INFO SecurityManager: Changing view acls groups to:
18/07/30 00:36:43 INFO SecurityManager: Changing modify acls groups to:
18/07/30 00:36:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
18/07/30 00:36:43 INFO Client: Submitting application application_1532879321912_0025 to ResourceManager
18/07/30 00:36:43 INFO YarnClientImpl: Submitted application application_1532879321912_0025
18/07/30 00:36:43 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1532879321912_0025 and attemptId None
18/07/30 00:36:44 INFO Client: Application report for application_1532879321912_0025 (state: ACCEPTED)
18/07/30 00:36:44 INFO Client:
         client token: N/A
         diagnostics: AM container is launched, waiting for AM container to Register with RM
         ApplicationMaster host: N/A
         ApplicationMaster RPC port: -1
         queue: default
         start time: 1532911003640
         final status: UNDEFINED
         tracking URL: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1532879321912_0025/
         user: root
18/07/30 00:36:45 INFO Client: Application report for application_1532879321912_0025 (state: ACCEPTED)
18/07/30 00:36:46 INFO Client: Application report for application_1532879321912_0025 (state: ACCEPTED)
18/07/30 00:36:47 INFO Client: Application report for application_1532879321912_0025 (state: ACCEPTED)
18/07/30 00:36:48 INFO Client: Application report for application_1532879321912_0025 (state: ACCEPTED)
18/07/30 00:36:49 INFO Client: Application report for application_1532879321912_0025 (state: ACCEPTED)
18/07/30 00:36:50 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> sandbox-hdp.hortonworks.com, PROXY_URI_BASES -> http://sandbox-hdp.hortonworks.com:8088/proxy/application_1532879321912_0025), /proxy/application_1532879321912_0025
18/07/30 00:36:50 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
18/07/30 00:36:50 INFO Client: Application report for application_1532879321912_0025 (state: ACCEPTED)
18/07/30 00:36:51 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
18/07/30 00:36:51 INFO Client: Application report for application_1532879321912_0025 (state: RUNNING)
18/07/30 00:36:51 INFO Client:
         client token: N/A
         diagnostics: N/A
         ApplicationMaster host: 172.17.0.2
         ApplicationMaster RPC port: 0
         queue: default
         start time: 1532911003640
         final status: UNDEFINED
         tracking URL: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1532879321912_0025/
         user: root
18/07/30 00:36:51 INFO YarnClientSchedulerBackend: Application application_1532879321912_0025 has started running.
18/07/30 00:36:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34249.
18/07/30 00:36:51 INFO NettyBlockTransferService: Server created on 172.17.0.2:34249
18/07/30 00:36:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/07/30 00:36:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.17.0.2, 34249, None)
18/07/30 00:36:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.17.0.2:34249 with 366.3 MB RAM, BlockManagerId(driver, 172.17.0.2, 34249, None)
18/07/30 00:36:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.17.0.2, 34249, None)
18/07/30 00:36:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.17.0.2, 34249, None)
18/07/30 00:36:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1f445f57{/metrics/json,null,AVAILABLE,@Spark}
18/07/30 00:36:52 INFO EventLoggingListener: Logging events to hdfs:///spark2-history/application_1532879321912_0025
18/07/30 00:36:55 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.17.0.2:54830) with ID 1
18/07/30 00:36:55 INFO BlockManagerMasterEndpoint: Registering block manager sandbox-hdp.hortonworks.com:35869 with 366.3 MB RAM, BlockManagerId(1, sandbox-hdp.hortonworks.com, 35869, None)
18/07/30 00:37:11 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
18/07/30 00:37:11 INFO SparkContext: Added file /usr/bid_classes.py at spark://172.17.0.2:38373/files/bid_classes.py with timestamp 1532911031137
18/07/30 00:37:11 INFO Utils: Copying /usr/bid_classes.py to /tmp/spark-5454d56e-73fb-462a-b5b1-4c2d826cee9d/userFiles-2c7eb7f1-a022-432e-9bf1-279d525fd99c/bid_classes.py
18/07/30 00:37:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 363.8 KB, free 365.9 MB)
18/07/30 00:37:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.0 KB, free 365.9 MB)
18/07/30 00:37:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.2:34249 (size: 32.0 KB, free: 366.3 MB)
18/07/30 00:37:11 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
18/07/30 00:37:11 INFO FileInputFormat: Total input paths to process : 1
18/07/30 00:37:11 INFO NetworkTopology: Adding a new node: /default-rack/172.17.0.2:50010
18/07/30 00:37:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/07/30 00:37:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/07/30 00:37:12 INFO SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:0
18/07/30 00:37:12 INFO DAGScheduler: Registering RDD 3 (groupBy at /usr/test.py:34)
18/07/30 00:37:12 INFO DAGScheduler: Got job 0 (saveAsTextFile at NativeMethodAccessorImpl.java:0) with 2 output partitions
18/07/30 00:37:12 INFO DAGScheduler: Final stage: ResultStage 1 (saveAsTextFile at NativeMethodAccessorImpl.java:0)
18/07/30 00:37:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
18/07/30 00:37:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
18/07/30 00:37:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /usr/test.py:34), which has no missing parents
18/07/30 00:37:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 365.9 MB)
18/07/30 00:37:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 365.9 MB)
18/07/30 00:37:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.17.0.2:34249 (size: 6.4 KB, free: 366.3 MB)
18/07/30 00:37:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/07/30 00:37:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /usr/test.py:34) (first 15 tasks are for partitions Vector(0, 1))
18/07/30 00:37:12 INFO YarnScheduler: Adding task set 0.0 with 2 tasks
18/07/30 00:37:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 4895 bytes)
18/07/30 00:37:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 6.4 KB, free: 366.3 MB)
18/07/30 00:37:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 32.0 KB, free: 366.3 MB)
18/07/30 00:37:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sandbox-hdp.hortonworks.com, executor 1, partition 1, RACK_LOCAL, 4895 bytes)
18/07/30 00:37:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5384 ms on sandbox-hdp.hortonworks.com (executor 1) (1/2)
18/07/30 00:37:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 3098 ms on sandbox-hdp.hortonworks.com (executor 1) (2/2)
18/07/30 00:37:20 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool
18/07/30 00:37:20 INFO DAGScheduler: ShuffleMapStage 0 (groupBy at /usr/test.py:34) finished in 8.452 s
18/07/30 00:37:20 INFO DAGScheduler: looking for newly runnable stages
18/07/30 00:37:20 INFO DAGScheduler: running: Set()
18/07/30 00:37:20 INFO DAGScheduler: waiting: Set(ResultStage 1)
18/07/30 00:37:20 INFO DAGScheduler: failed: Set()
18/07/30 00:37:20 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
18/07/30 00:37:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 98.5 KB, free 365.8 MB)
18/07/30 00:37:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.4 KB, free 365.8 MB)
18/07/30 00:37:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.17.0.2:34249 (size: 39.4 KB, free: 366.2 MB)
18/07/30 00:37:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/07/30 00:37:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
18/07/30 00:37:20 INFO YarnScheduler: Adding task set 1.0 with 2 tasks
18/07/30 00:37:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 4632 bytes)
18/07/30 00:37:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 39.4 KB, free: 366.2 MB)
18/07/30 00:37:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.17.0.2:54830
18/07/30 00:37:21 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 167 bytes
18/07/30 00:37:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, sandbox-hdp.hortonworks.com, executor 1, partition 1, NODE_LOCAL, 4632 bytes)
18/07/30 00:37:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 563 ms on sandbox-hdp.hortonworks.com (executor 1) (1/2)
18/07/30 00:37:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 298 ms on sandbox-hdp.hortonworks.com (executor 1) (2/2)
18/07/30 00:37:21 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool
18/07/30 00:37:21 INFO DAGScheduler: ResultStage 1 (saveAsTextFile at NativeMethodAccessorImpl.java:0) finished in 0.860 s
18/07/30 00:37:21 INFO DAGScheduler: Job 0 finished: saveAsTextFile at NativeMethodAccessorImpl.java:0, took 9.672728 s
18/07/30 00:37:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 363.9 KB, free 365.4 MB)
18/07/30 00:37:21 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.0 KB, free 365.4 MB)
18/07/30 00:37:21 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.2:34249 (size: 32.0 KB, free: 366.2 MB)
18/07/30 00:37:21 INFO SparkContext: Created broadcast 3 from textFile at NativeMethodAccessorImpl.java:0
18/07/30 00:37:21 INFO FileInputFormat: Total input paths to process : 1
18/07/30 00:37:21 INFO SparkContext: Starting job: collect at /usr/test.py:82
18/07/30 00:37:21 INFO DAGScheduler: Got job 1 (collect at /usr/test.py:82) with 2 output partitions
18/07/30 00:37:21 INFO DAGScheduler: Final stage: ResultStage 2 (collect at /usr/test.py:82)
18/07/30 00:37:21 INFO DAGScheduler: Parents of final stage: List()
18/07/30 00:37:21 INFO DAGScheduler: Missing parents: List()
18/07/30 00:37:21 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[11] at collect at /usr/test.py:82), which has no missing parents
18/07/30 00:37:21 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 5.5 KB, free 365.4 MB)
18/07/30 00:37:21 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 365.4 MB)
18/07/30 00:37:21 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.2:34249 (size: 3.3 KB, free: 366.2 MB)
18/07/30 00:37:21 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/07/30 00:37:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[11] at collect at /usr/test.py:82) (first 15 tasks are for partitions Vector(0, 1))
18/07/30 00:37:21 INFO YarnScheduler: Adding task set 2.0 with 2 tasks
18/07/30 00:37:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 4915 bytes)
18/07/30 00:37:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 3.3 KB, free: 366.2 MB)
18/07/30 00:37:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 32.0 KB, free: 366.2 MB)
18/07/30 00:37:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, sandbox-hdp.hortonworks.com, executor 1, partition 1, NODE_LOCAL, 4915 bytes)
18/07/30 00:37:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 128 ms on sandbox-hdp.hortonworks.com (executor 1) (1/2)
18/07/30 00:37:22 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 60 ms on sandbox-hdp.hortonworks.com (executor 1) (2/2)
18/07/30 00:37:22 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool
18/07/30 00:37:22 INFO DAGScheduler: ResultStage 2 (collect at /usr/test.py:82) finished in 0.182 s
18/07/30 00:37:22 INFO DAGScheduler: Job 1 finished: collect at /usr/test.py:82, took 0.192619 s
18/07/30 00:37:22 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 296.0 B, free 365.4 MB)
18/07/30 00:37:22 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 132.5 KB, free 365.2 MB)
18/07/30 00:37:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.2:34249 (size: 132.5 KB, free: 366.1 MB)
18/07/30 00:37:22 INFO SparkContext: Created broadcast 5 from broadcast at PythonRDD.scala:496
18/07/30 00:37:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/07/30 00:37:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/07/30 00:37:22 INFO SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:0
18/07/30 00:37:22 INFO DAGScheduler: Got job 2 (saveAsTextFile at NativeMethodAccessorImpl.java:0) with 2 output partitions
18/07/30 00:37:22 INFO DAGScheduler: Final stage: ResultStage 3 (saveAsTextFile at NativeMethodAccessorImpl.java:0)
18/07/30 00:37:22 INFO DAGScheduler: Parents of final stage: List()
18/07/30 00:37:22 INFO DAGScheduler: Missing parents: List()
18/07/30 00:37:22 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[14] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
18/07/30 00:37:22 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 97.2 KB, free 365.1 MB)
18/07/30 00:37:22 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 38.3 KB, free 365.1 MB)
18/07/30 00:37:22 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.2:34249 (size: 38.3 KB, free: 366.0 MB)
18/07/30 00:37:22 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/07/30 00:37:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
18/07/30 00:37:22 INFO YarnScheduler: Adding task set 3.0 with 2 tasks
18/07/30 00:37:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 4906 bytes)
18/07/30 00:37:22 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 38.3 KB, free: 366.2 MB)
18/07/30 00:37:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 132.5 KB, free: 366.0 MB)
18/07/30 00:38:06 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, sandbox-hdp.hortonworks.com, executor 1, partition 1, RACK_LOCAL, 4906 bytes)
18/07/30 00:38:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 43880 ms on sandbox-hdp.hortonworks.com (executor 1) (1/2)
18/07/30 00:38:49 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 43719 ms on sandbox-hdp.hortonworks.com (executor 1) (2/2)
18/07/30 00:38:49 INFO YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool
18/07/30 00:38:49 INFO DAGScheduler: ResultStage 3 (saveAsTextFile at NativeMethodAccessorImpl.java:0) finished in 87.602 s
18/07/30 00:38:49 INFO DAGScheduler: Job 2 finished: saveAsTextFile at NativeMethodAccessorImpl.java:0, took 87.686878 s
18/07/30 00:38:50 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 363.9 KB, free 364.8 MB)
18/07/30 00:38:50 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.0 KB, free 364.7 MB)
18/07/30 00:38:50 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.17.0.2:34249 (size: 32.0 KB, free: 366.0 MB)
18/07/30 00:38:50 INFO SparkContext: Created broadcast 7 from textFile at NativeMethodAccessorImpl.java:0
18/07/30 00:38:50 INFO FileInputFormat: Total input paths to process : 1
18/07/30 00:38:50 INFO SparkContext: Starting job: collect at /usr/test.py:98
18/07/30 00:38:50 INFO DAGScheduler: Got job 3 (collect at /usr/test.py:98) with 2 output partitions
18/07/30 00:38:50 INFO DAGScheduler: Final stage: ResultStage 4 (collect at /usr/test.py:98)
18/07/30 00:38:50 INFO DAGScheduler: Parents of final stage: List()
18/07/30 00:38:50 INFO DAGScheduler: Missing parents: List()
18/07/30 00:38:50 INFO DAGScheduler: Submitting ResultStage 4 (PythonRDD[21] at collect at /usr/test.py:98), which has no missing parents
18/07/30 00:38:50 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 5.4 KB, free 364.7 MB)
18/07/30 00:38:50 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.3 KB, free 364.7 MB)
18/07/30 00:38:50 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.17.0.2:34249 (size: 3.3 KB, free: 366.0 MB)
18/07/30 00:38:50 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/07/30 00:38:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (PythonRDD[21] at collect at /usr/test.py:98) (first 15 tasks are for partitions Vector(0, 1))
18/07/30 00:38:50 INFO YarnScheduler: Adding task set 4.0 with 2 tasks
18/07/30 00:38:50 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 4908 bytes)
18/07/30 00:38:50 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 3.3 KB, free: 366.0 MB)
18/07/30 00:38:50 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 32.0 KB, free: 366.0 MB)
18/07/30 00:38:50 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 9, sandbox-hdp.hortonworks.com, executor 1, partition 1, NODE_LOCAL, 4908 bytes)
18/07/30 00:38:50 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 87 ms on sandbox-hdp.hortonworks.com (executor 1) (1/2)
18/07/30 00:38:50 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 9) in 32 ms on sandbox-hdp.hortonworks.com (executor 1) (2/2)
18/07/30 00:38:50 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool
18/07/30 00:38:50 INFO DAGScheduler: ResultStage 4 (collect at /usr/test.py:98) finished in 0.119 s
18/07/30 00:38:50 INFO DAGScheduler: Job 3 finished: collect at /usr/test.py:98, took 0.130086 s
18/07/30 00:38:50 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 296.0 B, free 364.7 MB)
18/07/30 00:38:50 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 31.8 KB, free 364.7 MB)
18/07/30 00:38:50 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.17.0.2:34249 (size: 31.8 KB, free: 366.0 MB)
18/07/30 00:38:50 INFO SparkContext: Created broadcast 9 from broadcast at PythonRDD.scala:496
18/07/30 00:38:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/07/30 00:38:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/07/30 00:38:50 INFO SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:0
18/07/30 00:38:50 INFO DAGScheduler: Registering RDD 16 (groupBy at /usr/test.py:120)
18/07/30 00:38:50 INFO DAGScheduler: Got job 4 (saveAsTextFile at NativeMethodAccessorImpl.java:0) with 2 output partitions
18/07/30 00:38:50 INFO DAGScheduler: Final stage: ResultStage 6 (saveAsTextFile at NativeMethodAccessorImpl.java:0)
18/07/30 00:38:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/07/30 00:38:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/07/30 00:38:50 INFO DAGScheduler: Submitting ShuffleMapStage 5 (PairwiseRDD[16] at groupBy at /usr/test.py:120), which has no missing parents
18/07/30 00:38:50 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 12.0 KB, free 364.7 MB)
18/07/30 00:38:50 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.7 MB)
18/07/30 00:38:50 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.17.0.2:34249 (size: 7.7 KB, free: 365.9 MB)
18/07/30 00:38:50 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/07/30 00:38:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (PairwiseRDD[16] at groupBy at /usr/test.py:120) (first 15 tasks are for partitions Vector(0, 1))
18/07/30 00:38:50 INFO YarnScheduler: Adding task set 5.0 with 2 tasks
18/07/30 00:38:50 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 4895 bytes)
18/07/30 00:38:50 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 7.7 KB, free: 366.0 MB)
18/07/30 00:40:31 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 11, sandbox-hdp.hortonworks.com, executor 1, partition 1, RACK_LOCAL, 4895 bytes)
18/07/30 00:40:31 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 101555 ms on sandbox-hdp.hortonworks.com (executor 1) (1/2)
18/07/30 00:42:08 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 11) in 96556 ms on sandbox-hdp.hortonworks.com (executor 1) (2/2)
18/07/30 00:42:08 INFO YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool
18/07/30 00:42:08 INFO DAGScheduler: ShuffleMapStage 5 (groupBy at /usr/test.py:120) finished in 198.113 s
18/07/30 00:42:08 INFO DAGScheduler: looking for newly runnable stages
18/07/30 00:42:08 INFO DAGScheduler: running: Set()
18/07/30 00:42:08 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/07/30 00:42:08 INFO DAGScheduler: failed: Set()
18/07/30 00:42:08 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
18/07/30 00:42:08 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 98.4 KB, free 364.6 MB)
18/07/30 00:42:08 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 39.1 KB, free 364.5 MB)
18/07/30 00:42:08 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.17.0.2:34249 (size: 39.1 KB, free: 365.9 MB)
18/07/30 00:42:08 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/07/30 00:42:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
18/07/30 00:42:08 INFO YarnScheduler: Adding task set 6.0 with 2 tasks
18/07/30 00:42:08 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 4632 bytes)
18/07/30 00:42:08 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 39.1 KB, free: 365.9 MB)
18/07/30 00:42:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.17.0.2:54830
18/07/30 00:42:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 167 bytes
18/07/30 00:42:08 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on sandbox-hdp.hortonworks.com:35869 (size: 31.8 KB, free: 365.9 MB)
18/07/30 00:43:32 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, sandbox-hdp.hortonworks.com, executor 1, partition 1, NODE_LOCAL, 4632 bytes)
18/07/30 00:43:32 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 84309 ms on sandbox-hdp.hortonworks.com (executor 1) (1/2)
18/07/30 00:44:48 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 75532 ms on sandbox-hdp.hortonworks.com (executor 1) (2/2)
18/07/30 00:44:48 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool
18/07/30 00:44:48 INFO DAGScheduler: ResultStage 6 (saveAsTextFile at NativeMethodAccessorImpl.java:0) finished in 159.841 s
18/07/30 00:44:48 INFO DAGScheduler: Job 4 finished: saveAsTextFile at NativeMethodAccessorImpl.java:0, took 358.062930 s
18/07/30 00:44:48 INFO SparkContext: Invoking stop() from shutdown hook
18/07/30 00:44:48 INFO AbstractConnector: Stopped Spark@2170f1fc{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
18/07/30 00:44:48 INFO SparkUI: Stopped Spark web UI at http://172.17.0.2:4041
18/07/30 00:44:48 INFO YarnClientSchedulerBackend: Interrupting monitor thread
18/07/30 00:44:49 INFO YarnClientSchedulerBackend: Shutting down all executors
18/07/30 00:44:49 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
18/07/30 00:44:49 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
18/07/30 00:44:49 INFO YarnClientSchedulerBackend: Stopped
18/07/30 00:44:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/07/30 00:44:49 INFO MemoryStore: MemoryStore cleared
18/07/30 00:44:49 INFO BlockManager: BlockManager stopped
18/07/30 00:44:49 INFO BlockManagerMaster: BlockManagerMaster stopped
18/07/30 00:44:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/07/30 00:44:49 INFO SparkContext: Successfully stopped SparkContext
18/07/30 00:44:49 INFO ShutdownHookManager: Shutdown hook called
18/07/30 00:44:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-5454d56e-73fb-462a-b5b1-4c2d826cee9d/pyspark-b518fc42-c5e8-4263-98db-fc1d701bdc84
18/07/30 00:44:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-5454d56e-73fb-462a-b5b1-4c2d826cee9d